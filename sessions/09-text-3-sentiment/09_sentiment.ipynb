{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "09-Sentiment",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_EePCTyXn4h"
      },
      "source": [
        "##############################################################################\n",
        "## Foundations in Text Analytics - Sentiment Analysis\n",
        "##\n",
        "## Learning goals:\n",
        "##                 - reinforce text as a datasource\n",
        "##                 - python packages for handling our corpus for these specific tasks\n",
        "##                 - Sentiment analysis \n",
        "##                 - Sentiment analysis via ML\n",
        "##                 - Build your own sentiment classifier!\n",
        "##############################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knWtGcKX8m47"
      },
      "source": [
        "# installs\n",
        "! pip install newspaper3k\n",
        "! pip install spacy\n",
        "! pip install wordcloud\n",
        "! pip install emoji\n",
        "! pip install nltk\n",
        "! pip install scikit-plot\n",
        "! pip install umap-learn\n",
        "! pip install afinn\n",
        "! pip install textblob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A74mLOhN8nvw"
      },
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import scikitplot as skplot\n",
        "\n",
        "# some \"fun\" packages\n",
        "from wordcloud import WordCloud\n",
        "import emoji\n",
        "\n",
        "import re\n",
        "\n",
        "# text imports\n",
        "\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer,TfidfVectorizer  \n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from afinn import Afinn\n",
        "\n",
        "from newspaper import Article\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-8LzeQp8n4a"
      },
      "source": [
        "##################################### let's get warmed up\n",
        "## URL = https://bit.ly/37ShEj4\n",
        "## \n",
        "## scrape the text from the URL above\n",
        "## tokenize based on word characters\n",
        "## TRICKY - tokenize based on word characters and a hyphen (-)\n",
        "## include unigrams and bigrams\n",
        "## remove stopwords\n",
        "## how large is the vocab\n",
        "## TRICKY: top 5 tokens\n",
        "##\n",
        "## \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kyJWpeG5GxO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vezAskJMER9a"
      },
      "source": [
        "##################################### Sentiment 1\n",
        "##\n",
        "##  We will start basic = word/dictionary-based approach\n",
        "## \n",
        "## IDEA:  each word gets a score, sum up the score, thats it!\n",
        "## it's intuitive, easy to explain, and customizable\n",
        "## \n",
        "## Afinn - 2011\n",
        "## https://github.com/fnielsen/afinn\n",
        "##\n",
        "## TLDR\n",
        "## limited language support, but highlights an important concept\n",
        "## build our dictionary, and score\n",
        "## could even be emoticons!\n",
        "## https://github.com/fnielsen/afinn/tree/master/afinn/data\n",
        "##\n",
        "## "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tL0C1mcEp_e"
      },
      "source": [
        "# setup the english \"model\"\n",
        "afinn = Afinn(language='en')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T79iMJrJOaE"
      },
      "source": [
        "# let's just start with something basic\n",
        "afinn.score(\"Today is a great day!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2oOyGOnJPcJ"
      },
      "source": [
        "# let's try another\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKE-nLqeJPiA"
      },
      "source": [
        "############### Question:  What do you notice?  What happened (outside of getting a score)?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD77sYi0JPlo"
      },
      "source": [
        "## let's look at the data behind this\n",
        "\n",
        "# URL = \"https://raw.githubusercontent.com/fnielsen/afinn/master/afinn/data/AFINN-111.txt\"\n",
        "# ad = pd.read_csv(URL, sep='\\t', header=None, names=['token', 'score'])\n",
        "# ad.sample(7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cLwnOWIP1P3"
      },
      "source": [
        "# summary -- bounded between -5 and 5\n",
        "##  mean is slightly negative (negative values = negative)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_Ca4uOWKV6x"
      },
      "source": [
        "# what are the values for score\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC6ydvv9RG6g"
      },
      "source": [
        "# we can inspect easily to wrap our heads around the words\n",
        "# stop\n",
        "\n",
        "# ROWS = ad.token.str.contains(\"stop\")\n",
        "# ad.loc[ROWS, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pQXN1VfRMq4"
      },
      "source": [
        "# another search - lol\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7CIzcjwKWA3"
      },
      "source": [
        "# let's go back to a statement, see the score, and break it down\n",
        "\n",
        "# doc = \"love hate\"\n",
        "# afinn.score(doc)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPFTm2OlKWG7"
      },
      "source": [
        "# what is the list of floats being used for the score\n",
        "\n",
        "# afinn.scores(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AREdKRsrBDk-"
      },
      "source": [
        "# confirming that we can make ths more concrete, and that\n",
        "# the other words are not considered important for sentiment\n",
        "# in a lookup approach\n",
        "\n",
        "# afinn.scores(\"love hate relationship with this service\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfgqmmII5kkk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq7IoD-IKWK3"
      },
      "source": [
        "##################################### YOUR TURN\n",
        "##\n",
        "##  there is a table on big query\n",
        "##  datasets.bruins_twitter\n",
        "##\n",
        "##  get the records where the hour is 0,1,2,3\n",
        "##  this is not a select *, you have to filter records\n",
        "##  apply afinn sentiment to each record\n",
        "##  ensure that the data sorted by status_id\n",
        "##  plot the sentiment score over the records (this is a timeseries - like view)\n",
        "##  calculate the average sentiment by hour\n",
        "##\n",
        "## \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pr2kCTXb6NXm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYll3YMYGvlK"
      },
      "source": [
        "###############################  lets look at two records\n",
        "\n",
        "# IDS = [1204921609733070848, 1206041140165849089]\n",
        "# # sent = 0,-1\n",
        "# tweets.loc[tweets.status_id.isin(IDS), \"text\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KNNPy0LGvps"
      },
      "source": [
        "################## WHAT DO YOU NOTICE ABOVE\n",
        "################## should these be slightly neutral or negative?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ih5c9wYgdQYU"
      },
      "source": [
        "##################################### Quick departure\n",
        "## word clouds\n",
        "## you may have clients ask about this\n",
        "## \n",
        "## let's break this down\n",
        "##\n",
        "\n",
        "# we will use the article text from here\n",
        "# expects a string, more or less, not a list, per se\n",
        "\n",
        "\n",
        "# wc = WordCloud(background_color=\"white\")\n",
        "# wordcloud = wc.generate(article.text)\n",
        "\n",
        "# # Display the  plot:\n",
        "# plt.imshow(wordcloud)\n",
        "# plt.axis(\"off\")\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2TJwyblhTNS"
      },
      "source": [
        "#### run above a few times, look for\n",
        "## 1- the color of GPT, medical, and expo\n",
        "## 2- the placement relative to each other\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQAJRHpyhTUu"
      },
      "source": [
        "################################## THOUGHT EXPERIMENT/REVIEW OF ABOVE\n",
        "##\n",
        "## Ok, let's break this down\n",
        "## we have seen distance measures + PCA/TSNE/UMPA\n",
        "## in those situations, spatial placement matters\n",
        "## general best practices - color should mean something too\n",
        "## size in word clouds is fine\n",
        "## Takeaway:  this is really, really \"fun\" way to explore data\n",
        "##            but hardly one that should ever be considered anlaytics or findings (IN MY OPINION)\n",
        "##\n",
        "## WHY?   How does the shape of sunglasses help us understand the data? LOL\n",
        "## https://www.littlemissdata.com/blog/wordclouds\n",
        "## "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdJFTZQrhTYp"
      },
      "source": [
        "##################################### TextBlob - Sentiment\n",
        "## \n",
        "## NLP toolkit that goes beyond sentiment, so worth exploring\n",
        "## we will see spacy on Wednesday, so this is a nice segue\n",
        "## \n",
        "## The general framework: we operate on a document, not a corpus\n",
        "## the document is parsed for a variety of NLP tasks\n",
        "##\n",
        "## POS, sentiment, noun-phrases, even spelling correction\n",
        "##\n",
        "##\n",
        "\n",
        "# setup\n",
        "from textblob import TextBlob\n",
        "\n",
        "# a simple corpus to show the document orientation\n",
        "# corpus = [\"Today was a great day\", \"Today was a bad day\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T39r-L5IhTbW"
      },
      "source": [
        "# attempt to parse, this will fail!\n",
        "# TextBlob(corpus)\n",
        "\n",
        "## REVIEW THE TypeError"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0yWNPfYO9-K"
      },
      "source": [
        "# lets try this again\n",
        "\n",
        "# parsed = []\n",
        "# for doc in corpus:\n",
        "#   parsed.append(TextBlob(doc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rAxV2CAO-DT"
      },
      "source": [
        "# we have the objects \"parsed\", \n",
        "# we can see that the data are TextBlob objects\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmPOQzHnO-Gc"
      },
      "source": [
        "# what do we have, look at the first\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVPGc7wjO-Ie"
      },
      "source": [
        "# lets get the sentiment\n",
        "\n",
        "# sent = []\n",
        "# for p in parsed:\n",
        "#   sent.append(p.sentiment)\n",
        "\n",
        "# sent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7L2LAiyPXX1"
      },
      "source": [
        "############################### REVIEW\n",
        "# we can see above that we are still getting the objects, but we start to see some detail\n",
        "#\n",
        "# polarity = how positive/negative, which ranges from -1 to 1\n",
        "# subjectivity = 0 -> 1, or fact -> opinion\n",
        "#\n",
        "# not shown above, but textblob's model also handles modifier words which we will see in a moment\n",
        "#\n",
        "# ALSO: the model?  Trained on reviews that were labeled (movie reviews), and also draws from other projects\n",
        "#                   https://raw.githubusercontent.com/aesuli/SentiWordNet/master/data/SentiWordNet_3.0.0.txt\n",
        "#                   https://github.com/sloria/TextBlob/blob/90cc87ab0f9e25f37379079840ec43aba59af440/textblob/en/sentiments.py\n",
        "# Link below you can dive into the code for more view\n",
        "#                   https://github.com/sloria/TextBlob/blob/eb08c120d364e908646731d60b4e4c6c1712ff63/textblob/_text.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cr4nPVF8PXbX"
      },
      "source": [
        "# lets go back to the results though, we can pull out the scores as needed\n",
        "\n",
        "# sent = []\n",
        "# for doc in corpus:\n",
        "#   sent.append(TextBlob(doc).sentiment.polarity)\n",
        "\n",
        "# sent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuPQCaPBPXem"
      },
      "source": [
        "# NOTE:  that unlike afinn, these are not balanced, but perhaps because there is more than\n",
        "# just a lookup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1rnFNSQPXhM"
      },
      "source": [
        "# lets try some other examples\n",
        "\n",
        "# TextBlob(\"great\").sentiment.polarity\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y3m1JtkSjCz"
      },
      "source": [
        "###### you can see above that there are some smarts baked into this\n",
        "##     textblob is able to look at the words and modify as needed, based on the intensity of the word (not shown)\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkL90SJOSjGw"
      },
      "source": [
        "# one other note\n",
        "# Textblob ignores 1 letter words, just like sklearn does\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbK6UDxKSjJo"
      },
      "source": [
        "# subjectivity?\n",
        "\n",
        "# TextBlob(\"python is awesome\").sentiment.subjectivity\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZzc8VGPPXkA"
      },
      "source": [
        "##################################### Breakout\n",
        "##\n",
        "##  We will use the same bruins twitter dataset above\n",
        "##  refer to above if you want to re-query the data\n",
        "##  \n",
        "## \n",
        "##  calculate the polarity (sentiment) and subjectivity for each tweet\n",
        "##  create a scatterplot to evaluate the both metrics for the dataset\n",
        "##\n",
        "##   next plot the relationship between afinn score and textblob score\n",
        "## "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flY_inxB6uk1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54fxQCmCXQcU"
      },
      "source": [
        "##################################### Vader sentiment\n",
        "## Very brief review\n",
        "## There are other approaches that attempt the modified approach\n",
        "## you should inspect them at a granular level to ensure that these work as you like\n",
        "## \n",
        "## But for sake of completeness, lets see the output\n",
        "##\n",
        "## for a deeper review on compound scores\n",
        "## https://stackoverflow.com/questions/40325980/how-is-the-vader-compound-polarity-score-calculated-in-python-nltk\n",
        "##  -- sum of normalized scores, and is not directly related to the pos/negative/netural\n",
        "##  https://github.com/cjhutto/vaderSentiment#about-the-scoring\n",
        "##\n",
        "## we get pos/neutral/negative distros \n",
        "## and a compound score which is what mostly used in practice\n",
        "## > .05 = positive\n",
        "## < -.05 = negative\n",
        "## else neutral\n",
        "## \n",
        "## like Textblob, its a model with modifiers and intensifiers\n",
        "## but this model was trained on social media, so perhaps it may fit your data better\n",
        "## AGAIN:  these tools help us get a report off the ground quickly, but we always should review\n",
        "## "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVX7aoV4XQez"
      },
      "source": [
        "# vader installs via nltk\n",
        "\n",
        "# nltk.download('vader_lexicon')\n",
        "# from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOIb7Z8vXQgh"
      },
      "source": [
        "# init\n",
        "\n",
        "# vader = SentimentIntensityAnalyzer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD9C6r_IXQjF"
      },
      "source": [
        "# lets play around -- whats nice is the distro can be a plot you use to highlight how this is subjective\n",
        "\n",
        "# vader.polarity_scores(\"Today is a great day\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kna1-s4hj4y"
      },
      "source": [
        "# but does punctuation matter?\n",
        "\n",
        "# corpus = [\"today was a good day\", \"today was a good day!\"]\n",
        "# test = []\n",
        "# for doc in corpus:\n",
        "#   test.append(vader.polarity_scores(doc))\n",
        "\n",
        "# test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-3ObWoZeWpA"
      },
      "source": [
        "# and if you wanted to look at the tweets\n",
        "# this might take a few moments!\n",
        "\n",
        "# def vader_model(text):\n",
        "#   vader_score = SentimentIntensityAnalyzer()\n",
        "#   sent = vader_score.polarity_scores(text)\n",
        "#   return sent.get(\"compound\", 0)\n",
        "\n",
        "# tweets['vader'] = tweets.text.apply(vader_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mkyZFi1eWsr"
      },
      "source": [
        "# a few records\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdV8aP1beWvw"
      },
      "source": [
        "## lets go back to those ids from before!\n",
        "\n",
        "# tweets.loc[tweets.status_id.isin(IDS), :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adeSOLsbf3E6"
      },
      "source": [
        "###################### above highlights that we might need to build our own!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR7xQyKQh3at"
      },
      "source": [
        "##################################### ML approach\n",
        "## \n",
        "## Sometimes we need to roll our own\n",
        "## \n",
        "## What does this mean?\n",
        "## 1. collect a dataset\n",
        "## 2. annotate the data with our own business rules\n",
        "##  --------> Label studio?\n",
        "## 3. we can use some of the tools above \n",
        "## ---------> generate a score, define a threshold, give labels\n",
        "## ---------> fit a model on labels\n",
        "## ---------> review, iterate, review, iterate\n",
        "##\n",
        "## Why build our own\n",
        "## \n",
        "## - out of the box generalize (thats a theme you have heard me say)\n",
        "## - domain specific words (for example, dataset above shows sports terms that are positive but not captured\n",
        "## - also, sarcasm is hard to detect even with modifier approaches\n",
        "##\n",
        "## "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFLwfXyWh3dV"
      },
      "source": [
        "# there is an airlines tweets dataset on biq query\n",
        "# bring in questrom.datasets.airlines-tweets\n",
        "# just the tweet_id, airline_sentiment, airline, and text columns\n",
        "\n",
        "# SQL = \"\"\"select tweet_id, \n",
        "#                 airline_sentiment, \n",
        "#                 airline, \n",
        "#                 text \n",
        "#          from `questrom.datasets.airlines-tweets`\n",
        "# \"\"\"\n",
        "# airlines = pd.read_gbq(SQL, \"questrom\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yENJ-DGyhb1I"
      },
      "source": [
        "# shape and a few records"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlH9AFayhb6o"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M54rf85hb9J"
      },
      "source": [
        "# what do we have for a label distribution?\n",
        "\n",
        "# airlines.airline_sentiment.value_counts(normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0t00kZHhb_Q"
      },
      "source": [
        "# lets assume our excellent back office staff has labeled these datasets properly\n",
        "# huge assumption, right!\n",
        "# we will parse the tweets, convert emojis, keep top 1000 vocab\n",
        "# and then create our own ML-based sentiment classifier\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuIz5bJFsB7W"
      },
      "source": [
        "# example of demojizing a text - just parses them out!\n",
        "\n",
        "# txt = \"great , but I have to go with #CarrieUnderwood üòçüëå\"\n",
        "# emoji.demojize(txt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9fQ5UIup7RO"
      },
      "source": [
        "# lets setup the flow of a model \n",
        "\n",
        "# from nltk.tokenize import TweetTokenizer\n",
        "# import emoji\n",
        "\n",
        "# SW = stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjsbwqeFp7Vc"
      },
      "source": [
        "# parse the airline tweets into a ML dataset\n",
        "\n",
        "# def tokenizer(text):\n",
        "#   social = TweetTokenizer()\n",
        "#   # replace emojis with string representations\n",
        "#   text = emoji.demojize(text)\n",
        "#   # if two emojis are stacked, add a whitespace in between\n",
        "#   text = text.replace(\"::\", \": :\")\n",
        "#   return social.tokenize(text)\n",
        "\n",
        "# cv = CountVectorizer(tokenizer=tokenizer, stop_words=SW, max_features=1000)\n",
        "\n",
        "# tokens = cv.fit_transform(airlines.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oq0IiVsKp7Yv"
      },
      "source": [
        "# into a dataframe\n",
        "\n",
        "# adf = pd.DataFrame(tokens.toarray(), columns=cv.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruYK66dRp7bb"
      },
      "source": [
        "# view a few entries with .iloc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PcNyInzp7eK"
      },
      "source": [
        "# top tokens\n",
        "\n",
        "# adf.sum(axis=0).sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRwS3j3ysZsj"
      },
      "source": [
        "############# notice above, what could we do better?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOv6WLCZsZwB"
      },
      "source": [
        "# regardless lets fit a decision tree classifier\n",
        "\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# tree = DecisionTreeClassifier(max_depth=5, min_samples_split=40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPKLDJAAsZzL"
      },
      "source": [
        "# validation\n",
        "\n",
        "# X = tokens.toarray()\n",
        "# y = airlines.airline_sentiment\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, stratify=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZPqTiCJsZ1I"
      },
      "source": [
        "# fit the tree\n",
        "\n",
        "# tree.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5A9saxFKsZ22"
      },
      "source": [
        "# apply the tree\n",
        "\n",
        "# preds = tree.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L17SfGpitl7N"
      },
      "source": [
        "# the report\n",
        "\n",
        "# from sklearn.metrics import classification_report\n",
        "\n",
        "# cr = classification_report(y_test, preds)\n",
        "# print(cr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31fRyktywSc5"
      },
      "source": [
        "############################ THOUGHT EXERCISE\n",
        "## how might you improve this?\n",
        "## this is good practice!\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}